"use strict";(globalThis.webpackChunkphysical_ai_book=globalThis.webpackChunkphysical_ai_book||[]).push([[2441],{8002(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>m,frontMatter:()=>t,metadata:()=>a,toc:()=>l});const a=JSON.parse('{"id":"module-3-ai-robot-brain/isaac-ros-components","title":"Isaac ROS Components and Python Code Examples","description":"NVIDIA Isaac ROS provides a collection of GPU-accelerated packages that enable efficient perception, navigation, and manipulation tasks for robotics applications. This section covers key Isaac ROS components with practical Python code examples.","source":"@site/docs/module-3-ai-robot-brain/isaac-ros-components.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/isaac-ros-components","permalink":"/physical-ai-humanoid-robotics-book/docs/module-3-ai-robot-brain/isaac-ros-components","draft":false,"unlisted":false,"editUrl":"https://github.com/your-organization/physical-ai-humanoid-robotics-book/edit/main/book/docs/module-3-ai-robot-brain/isaac-ros-components.md","tags":[],"version":"current","sidebarPosition":11,"frontMatter":{"sidebar_position":11}}');var i=s(4848),o=s(8453);const t={sidebar_position:11},r="Isaac ROS Components and Python Code Examples",c={},l=[{value:"Isaac ROS Common Components",id:"isaac-ros-common-components",level:2},{value:"Isaac ROS Common Utilities",id:"isaac-ros-common-utilities",level:3},{value:"Isaac ROS Image Pipeline",id:"isaac-ros-image-pipeline",level:2},{value:"Image Processing Pipeline",id:"image-processing-pipeline",level:3},{value:"Isaac ROS Point Cloud Utilities",id:"isaac-ros-point-cloud-utilities",level:2},{value:"Point Cloud Processing",id:"point-cloud-processing",level:3},{value:"Isaac ROS Visual SLAM Integration",id:"isaac-ros-visual-slam-integration",level:2},{value:"Working with Isaac Visual SLAM",id:"working-with-isaac-visual-slam",level:3},{value:"Isaac ROS Navigation Integration",id:"isaac-ros-navigation-integration",level:2},{value:"Navigation with Isaac Components",id:"navigation-with-isaac-components",level:3},{value:"Isaac ROS Detection and Perception",id:"isaac-ros-detection-and-perception",level:2},{value:"Object Detection Integration",id:"object-detection-integration",level:3},{value:"Isaac ROS Best Practices",id:"isaac-ros-best-practices",level:2},{value:"Efficient Isaac ROS Programming",id:"efficient-isaac-ros-programming",level:3}];function p(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"isaac-ros-components-and-python-code-examples",children:"Isaac ROS Components and Python Code Examples"})}),"\n",(0,i.jsx)(n.p,{children:"NVIDIA Isaac ROS provides a collection of GPU-accelerated packages that enable efficient perception, navigation, and manipulation tasks for robotics applications. This section covers key Isaac ROS components with practical Python code examples."}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-common-components",children:"Isaac ROS Common Components"}),"\n",(0,i.jsx)(n.h3,{id:"isaac-ros-common-utilities",children:"Isaac ROS Common Utilities"}),"\n",(0,i.jsx)(n.p,{children:"Isaac ROS common provides foundational utilities and base classes:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Example of using Isaac ROS common utilities\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom geometry_msgs.msg import TransformStamped\nfrom tf2_ros import TransformBroadcaster\nimport numpy as np\n\nclass IsaacCommonExampleNode(Node):\n    def __init__(self):\n        super().__init__('isaac_common_example')\n        \n        # Set up QoS profiles for Isaac ROS\n        self.image_qos = QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE,\n            history=HistoryPolicy.KEEP_LAST\n        )\n        \n        # Create subscription with Isaac-appropriate QoS\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            self.image_qos\n        )\n        \n        # TF broadcaster for Isaac coordinate frames\n        self.tf_broadcaster = TransformBroadcaster(self)\n        \n        self.get_logger().info('Isaac Common Example Node initialized')\n    \n    def image_callback(self, msg):\n        # Process image with Isaac common utilities\n        self.get_logger().info(f'Received image: {msg.width}x{msg.height}')\n        \n        # Example: Transform broadcasting\n        self.broadcast_transform()\n    \n    def broadcast_transform(self):\n        t = TransformStamped()\n        \n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = 'map'\n        t.child_frame_id = 'camera_link'\n        \n        t.transform.translation.x = 0.0\n        t.transform.translation.y = 0.0\n        t.transform.translation.z = 1.0\n        t.transform.rotation.x = 0.0\n        t.transform.rotation.y = 0.0\n        t.transform.rotation.z = 0.0\n        t.transform.rotation.w = 1.0\n        \n        self.tf_broadcaster.sendTransform(t)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-image-pipeline",children:"Isaac ROS Image Pipeline"}),"\n",(0,i.jsx)(n.h3,{id:"image-processing-pipeline",children:"Image Processing Pipeline"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Isaac ROS image pipeline example\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass IsaacImagePipelineNode(Node):\n    def __init__(self):\n        super().__init__('isaac_image_pipeline')\n        \n        # Initialize CV bridge\n        self.bridge = CvBridge()\n        \n        # Create subscriptions\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10\n        )\n        \n        self.info_sub = self.create_subscription(\n            CameraInfo,\n            '/camera/camera_info',\n            self.info_callback,\n            10\n        )\n        \n        # Create publishers\n        self.rectified_pub = self.create_publisher(\n            Image,\n            '/camera/image_rect',\n            10\n        )\n        \n        self.processed_pub = self.create_publisher(\n            Image,\n            '/camera/image_processed',\n            10\n        )\n        \n        # Internal state\n        self.camera_matrix = None\n        self.distortion_coeffs = None\n        \n    def info_callback(self, msg):\n        \"\"\"Handle camera info messages\"\"\"\n        self.camera_matrix = np.array(msg.k).reshape(3, 3)\n        self.distortion_coeffs = np.array(msg.d)\n        \n    def image_callback(self, msg):\n        \"\"\"Process incoming image messages\"\"\"\n        try:\n            # Convert ROS image to OpenCV\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n            \n            # Apply camera rectification if calibration is available\n            if self.camera_matrix is not None and self.distortion_coeffs is not None:\n                cv_rectified = cv2.undistort(\n                    cv_image, \n                    self.camera_matrix, \n                    self.distortion_coeffs,\n                    None,\n                    self.camera_matrix  # New camera matrix (same as original)\n                )\n                \n                # Publish rectified image\n                rectified_msg = self.bridge.cv2_to_imgmsg(cv_rectified, encoding='bgr8')\n                rectified_msg.header = msg.header\n                self.rectified_pub.publish(rectified_msg)\n            else:\n                cv_rectified = cv_image\n            \n            # Apply additional processing\n            cv_processed = self.apply_processing(cv_rectified)\n            \n            # Publish processed image\n            processed_msg = self.bridge.cv2_to_imgmsg(cv_processed, encoding='bgr8')\n            processed_msg.header = msg.header\n            self.processed_pub.publish(processed_msg)\n            \n        except Exception as e:\n            self.get_logger().error(f'Error processing image: {e}')\n    \n    def apply_processing(self, image):\n        \"\"\"Apply image processing operations\"\"\"\n        # Example processing: edge detection\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        edges = cv2.Canny(gray, 50, 150)\n        \n        # Convert back to BGR for output\n        processed = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n        \n        return processed\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-point-cloud-utilities",children:"Isaac ROS Point Cloud Utilities"}),"\n",(0,i.jsx)(n.h3,{id:"point-cloud-processing",children:"Point Cloud Processing"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Isaac ROS point cloud utilities\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import PointCloud2, PointField\nfrom sensor_msgs_py import point_cloud2\nfrom std_msgs.msg import Header\nimport numpy as np\nimport struct\n\nclass IsaacPointCloudNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_pointcloud\')\n        \n        # Subscription for point cloud data\n        self.pc_sub = self.create_subscription(\n            PointCloud2,\n            \'/velodyne_points\',\n            self.pointcloud_callback,\n            10\n        )\n        \n        # Publisher for processed point cloud\n        self.pc_pub = self.create_publisher(\n            PointCloud2,\n            \'/pointcloud_processed\',\n            10\n        )\n        \n    def pointcloud_callback(self, msg):\n        """Process incoming point cloud data"""\n        try:\n            # Read points from PointCloud2 message\n            points = list(point_cloud2.read_points(msg, \n                                                 field_names=("x", "y", "z", "intensity"), \n                                                 skip_nans=True))\n            \n            if not points:\n                return\n                \n            # Convert to numpy array\n            points_array = np.array(points, dtype=np.float32)\n            \n            # Apply processing (e.g., ground plane removal)\n            processed_points = self.remove_ground_plane(points_array)\n            \n            # Create new PointCloud2 message\n            processed_msg = self.create_pointcloud2_msg(\n                processed_points, \n                msg.header\n            )\n            \n            # Publish processed point cloud\n            self.pc_pub.publish(processed_msg)\n            \n        except Exception as e:\n            self.get_logger().error(f\'Error processing point cloud: {e}\')\n    \n    def remove_ground_plane(self, points):\n        """Simple ground plane removal using height thresholding"""\n        # For demonstration, remove points below z=0.5m\n        ground_threshold = 0.5\n        non_ground_mask = points[:, 2] > ground_threshold\n        return points[non_ground_mask]\n    \n    def create_pointcloud2_msg(self, points, header):\n        """Create a PointCloud2 message from numpy array"""\n        # Define fields for PointCloud2\n        fields = [\n            PointField(name=\'x\', offset=0, datatype=PointField.FLOAT32, count=1),\n            PointField(name=\'y\', offset=4, datatype=PointField.FLOAT32, count=1),\n            PointField(name=\'z\', offset=8, datatype=PointField.FLOAT32, count=1),\n            PointField(name=\'intensity\', offset=12, datatype=PointField.FLOAT32, count=1)\n        ]\n        \n        # Create PointCloud2 message\n        pc2_msg = PointCloud2()\n        pc2_msg.header = header\n        pc2_msg.height = 1\n        pc2_msg.width = len(points)\n        pc2_msg.fields = fields\n        pc2_msg.is_bigendian = False\n        pc2_msg.point_step = 16  # 4 fields * 4 bytes each\n        pc2_msg.row_step = pc2_msg.point_step * pc2_msg.width\n        pc2_msg.is_dense = True\n        \n        # Pack points into binary data\n        data = []\n        for point in points:\n            data.append(struct.pack(\'ffff\', point[0], point[1], point[2], point[3] if len(point) > 3 else 0.0))\n        \n        pc2_msg.data = b\'\'.join(data)\n        \n        return pc2_msg\n'})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-visual-slam-integration",children:"Isaac ROS Visual SLAM Integration"}),"\n",(0,i.jsx)(n.h3,{id:"working-with-isaac-visual-slam",children:"Working with Isaac Visual SLAM"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Isaac Visual SLAM integration example\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, CameraInfo\nfrom geometry_msgs.msg import PoseStamped, TransformStamped\nfrom nav_msgs.msg import Odometry\nfrom tf2_ros import TransformBroadcaster\nimport numpy as np\n\nclass IsaacVSLAMIntegrationNode(Node):\n    def __init__(self):\n        super().__init__('isaac_vslam_integration')\n        \n        # Subscriptions for VSLAM input\n        self.rgb_sub = self.create_subscription(\n            Image,\n            '/camera/rgb/image_rect_color',\n            self.rgb_callback,\n            10\n        )\n        \n        self.depth_sub = self.create_subscription(\n            Image,\n            '/camera/depth/image_rect_raw',\n            self.depth_callback,\n            10\n        )\n        \n        self.camera_info_sub = self.create_subscription(\n            CameraInfo,\n            '/camera/rgb/camera_info',\n            self.camera_info_callback,\n            10\n        )\n        \n        # Subscriptions for VSLAM output (simulated)\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/visual_slam/odometry',\n            self.odom_callback,\n            10\n        )\n        \n        # Publishers\n        self.pose_pub = self.create_publisher(\n            PoseStamped,\n            '/visual_slam/pose',\n            10\n        )\n        \n        # TF broadcaster\n        self.tf_broadcaster = TransformBroadcaster(self)\n        \n        # Internal state\n        self.camera_info = None\n        self.latest_pose = None\n        \n    def camera_info_callback(self, msg):\n        self.camera_info = msg\n        \n    def rgb_callback(self, msg):\n        # This would feed into Isaac's VSLAM pipeline\n        self.get_logger().info('RGB image received for VSLAM processing')\n        \n    def depth_callback(self, msg):\n        # This would feed into Isaac's VSLAM pipeline\n        self.get_logger().info('Depth image received for VSLAM processing')\n    \n    def odom_callback(self, msg):\n        \"\"\"Handle odometry from VSLAM\"\"\"\n        # Extract pose from odometry\n        pose = PoseStamped()\n        pose.header = msg.header\n        pose.pose = msg.pose.pose\n        \n        # Store for TF broadcasting\n        self.latest_pose = pose\n        \n        # Publish pose\n        self.pose_pub.publish(pose)\n        \n        # Broadcast transform\n        self.broadcast_pose_transform(pose)\n    \n    def broadcast_pose_transform(self, pose_stamped):\n        \"\"\"Broadcast pose as transform\"\"\"\n        t = TransformStamped()\n        \n        t.header.stamp = self.get_clock().now().to_msg()\n        t.header.frame_id = 'map'\n        t.child_frame_id = 'base_link'\n        \n        t.transform.translation.x = pose_stamped.pose.position.x\n        t.transform.translation.y = pose_stamped.pose.position.y\n        t.transform.translation.z = pose_stamped.pose.position.z\n        t.transform.rotation = pose_stamped.pose.orientation\n        \n        self.tf_broadcaster.sendTransform(t)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-navigation-integration",children:"Isaac ROS Navigation Integration"}),"\n",(0,i.jsx)(n.h3,{id:"navigation-with-isaac-components",children:"Navigation with Isaac Components"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Isaac Navigation integration example\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Twist\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom visualization_msgs.msg import MarkerArray\nfrom action_msgs.msg import GoalStatus\nfrom nav2_msgs.action import NavigateToPose\nfrom rclpy.action import ActionClient\nimport numpy as np\n\nclass IsaacNavigationNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_navigation\')\n        \n        # Action client for navigation\n        self.nav_client = ActionClient(self, NavigateToPose, \'navigate_to_pose\')\n        \n        # Subscriptions\n        self.map_sub = self.create_subscription(\n            OccupancyGrid,\n            \'/map\',\n            self.map_callback,\n            10\n        )\n        \n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n        \n        # Publishers\n        self.cmd_vel_pub = self.create_publisher(\n            Twist,\n            \'/cmd_vel\',\n            10\n        )\n        \n        self.path_viz_pub = self.create_publisher(\n            MarkerArray,\n            \'/path_visualization\',\n            10\n        )\n        \n        # Internal state\n        self.map_data = None\n        self.current_path = None\n        self.navigation_goal = None\n        \n    def send_navigation_goal(self, x, y, theta=0.0):\n        """Send a navigation goal to Isaac\'s navigation system"""\n        # Wait for action server\n        if not self.nav_client.wait_for_server(timeout_sec=5.0):\n            self.get_logger().error(\'Navigation action server not available\')\n            return\n        \n        # Create goal message\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = \'map\'\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n        goal_msg.pose.pose.position.x = x\n        goal_msg.pose.pose.position.y = y\n        goal_msg.pose.pose.orientation.z = np.sin(theta / 2.0)\n        goal_msg.pose.pose.orientation.w = np.cos(theta / 2.0)\n        \n        # Send goal\n        self.future = self.nav_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.navigation_feedback_callback\n        )\n        \n        self.future.add_done_callback(self.navigation_result_callback)\n        \n    def navigation_feedback_callback(self, feedback_msg):\n        """Handle navigation feedback"""\n        self.get_logger().info(f\'Navigation progress: {feedback_msg.feedback.current_pose}\')\n        \n    def navigation_result_callback(self, future):\n        """Handle navigation result"""\n        goal_result = future.result()\n        status = goal_result.status\n        \n        if status == GoalStatus.STATUS_SUCCEEDED:\n            self.get_logger().info(\'Navigation succeeded!\')\n        else:\n            self.get_logger().error(f\'Navigation failed with status: {status}\')\n    \n    def map_callback(self, msg):\n        """Handle map updates"""\n        self.map_data = np.array(msg.data).reshape(msg.info.height, msg.info.width)\n        self.get_logger().info(f\'Received map: {msg.info.width}x{msg.info.height}\')\n    \n    def path_callback(self, msg):\n        """Handle path updates"""\n        self.current_path = msg.poses\n        self.visualize_path(msg.poses)\n    \n    def visualize_path(self, poses):\n        """Visualize the current path"""\n        marker_array = MarkerArray()\n        \n        for i, pose in enumerate(poses):\n            marker = Marker()\n            marker.header.frame_id = \'map\'\n            marker.header.stamp = self.get_clock().now().to_msg()\n            marker.ns = \'path\'\n            marker.id = i\n            marker.type = Marker.SPHERE\n            marker.action = Marker.ADD\n            \n            marker.pose = pose.pose\n            marker.scale.x = 0.1\n            marker.scale.y = 0.1\n            marker.scale.z = 0.1\n            marker.color.a = 1.0\n            marker.color.r = 1.0\n            marker.color.g = 0.0\n            marker.color.b = 0.0\n            \n            marker_array.markers.append(marker)\n        \n        self.path_viz_pub.publish(marker_array)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-detection-and-perception",children:"Isaac ROS Detection and Perception"}),"\n",(0,i.jsx)(n.h3,{id:"object-detection-integration",children:"Object Detection Integration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Isaac object detection integration\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom isaac_ros_msgs.msg import Detection2DArray, Detection2D, ObjectHypothesisWithPose\nfrom visualization_msgs.msg import MarkerArray\nfrom cv_bridge import CvBridge\nimport numpy as np\n\nclass IsaacDetectionNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_detection\')\n        \n        # Initialize CV bridge\n        self.bridge = CvBridge()\n        \n        # Subscriptions\n        self.image_sub = self.create_subscription(\n            Image,\n            \'/camera/image_rect\',\n            self.image_callback,\n            10\n        )\n        \n        # Isaac detection subscription\n        self.detection_sub = self.create_subscription(\n            Detection2DArray,\n            \'/detectnet/detections\',\n            self.detection_callback,\n            10\n        )\n        \n        # Publishers\n        self.detection_viz_pub = self.create_publisher(\n            MarkerArray,\n            \'/detection_visualization\',\n            10\n        )\n        \n        self.detection_pub = self.create_publisher(\n            Detection2DArray,\n            \'/processed_detections\',\n            10\n        )\n        \n    def image_callback(self, msg):\n        """Process image for detection"""\n        try:\n            # Convert image for processing\n            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding=\'bgr8\')\n            \n            # In a real Isaac setup, this would trigger detection\n            # For this example, we\'ll just log the event\n            self.get_logger().info(f\'Processing image for detection: {msg.width}x{msg.height}\')\n            \n        except Exception as e:\n            self.get_logger().error(f\'Error processing image: {e}\')\n    \n    def detection_callback(self, msg):\n        """Process incoming detections"""\n        processed_detections = Detection2DArray()\n        processed_detections.header = msg.header\n        \n        for detection in msg.detections:\n            # Process each detection\n            processed_detection = self.process_single_detection(detection)\n            if processed_detection:\n                processed_detections.detections.append(processed_detection)\n        \n        # Publish processed detections\n        self.detection_pub.publish(processed_detections)\n        \n        # Visualize detections\n        self.visualize_detections(processed_detections)\n    \n    def process_single_detection(self, detection):\n        """Process a single detection"""\n        # Apply filtering, validation, etc.\n        if detection.bbox.size_x * detection.bbox.size_y > 100:  # Min size filter\n            # Apply confidence threshold\n            if detection.results and detection.results[0].hypothesis.score > 0.5:\n                return detection\n        \n        return None  # Filter out this detection\n    \n    def visualize_detections(self, detections):\n        """Visualize detections as markers"""\n        marker_array = MarkerArray()\n        \n        for i, detection in enumerate(detections.detections):\n            # Create marker for bounding box\n            marker = Marker()\n            marker.header = detections.header\n            marker.ns = \'detections\'\n            marker.id = i\n            marker.type = Marker.LINE_STRIP\n            marker.action = Marker.ADD\n            \n            # Calculate bounding box corners\n            center_x = detection.bbox.center.x\n            center_y = detection.bbox.center.y\n            size_x = detection.bbox.size_x\n            size_y = detection.bbox.size_y\n            \n            # Define corners\n            corners = [\n                [center_x - size_x/2, center_y - size_y/2, 0.0],\n                [center_x + size_x/2, center_y - size_y/2, 0.0],\n                [center_x + size_x/2, center_y + size_y/2, 0.0],\n                [center_x - size_x/2, center_y + size_y/2, 0.0],\n                [center_x - size_x/2, center_y - size_y/2, 0.0]  # Close the loop\n            ]\n            \n            for corner in corners:\n                point = Point()\n                point.x, point.y, point.z = corner\n                marker.points.append(point)\n            \n            marker.scale.x = 0.05  # Line width\n            marker.color.a = 0.8\n            marker.color.r = 1.0\n            marker.color.g = 0.0\n            marker.color.b = 0.0\n            \n            marker_array.markers.append(marker)\n        \n        self.detection_viz_pub.publish(marker_array)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"isaac-ros-best-practices",children:"Isaac ROS Best Practices"}),"\n",(0,i.jsx)(n.h3,{id:"efficient-isaac-ros-programming",children:"Efficient Isaac ROS Programming"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Best practices for Isaac ROS components\nimport rclpy\nfrom rclpy.node import Node\nfrom rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy, DurabilityPolicy\nfrom sensor_msgs.msg import Image\nimport numpy as np\n\nclass IsaacBestPracticesNode(Node):\n    def __init__(self):\n        super().__init__(\'isaac_best_practices\')\n        \n        # Use appropriate QoS profiles for Isaac\n        self.isaac_qos = QoSProfile(\n            depth=1,\n            reliability=ReliabilityPolicy.RELIABLE,\n            durability=DurabilityPolicy.VOLATILE,\n            history=HistoryPolicy.KEEP_LAST\n        )\n        \n        # Create subscription with Isaac-appropriate QoS\n        self.image_sub = self.create_subscription(\n            Image,\n            \'/camera/image_raw\',\n            self.image_callback,\n            self.isaac_qos\n        )\n        \n        # Pre-allocate buffers to reduce memory allocation\n        self.image_buffer = None\n        self.processing_buffer = None\n        \n        # Set up timer for periodic tasks\n        self.timer = self.create_timer(0.1, self.periodic_tasks)\n        \n    def image_callback(self, msg):\n        """Process image with best practices"""\n        # Check if we need to resize our buffers\n        if (self.image_buffer is None or \n            self.image_buffer.shape != (msg.height, msg.width, 3)):\n            self.image_buffer = np.zeros((msg.height, msg.width, 3), dtype=np.uint8)\n            self.processing_buffer = np.zeros((msg.height, msg.width, 3), dtype=np.uint8)\n        \n        # Process image in-place to minimize allocations\n        self.process_image_efficiently(msg)\n    \n    def process_image_efficiently(self, msg):\n        """Efficient image processing with minimal allocations"""\n        # In a real Isaac setup, this would interface with GPU-accelerated processing\n        # For this example, we\'ll just demonstrate the pattern\n        self.get_logger().info(f\'Processing image efficiently: {msg.width}x{msg.height}\')\n        \n        # Example: Apply a simple operation without creating new arrays\n        # (In real Isaac, this would be GPU-accelerated)\n        # self.processing_buffer[:] = self.image_buffer  # Copy in place\n        # Apply processing to processing_buffer\n        \n    def periodic_tasks(self):\n        """Run periodic tasks"""\n        # Monitor performance, health, etc.\n        self.get_logger().debug(\'Running periodic tasks\')\n'})}),"\n",(0,i.jsx)(n.p,{children:"These examples demonstrate how to work with Isaac ROS components in Python, following best practices for efficient and effective integration with the Isaac platform. The code examples cover common use cases and patterns for working with Isaac's GPU-accelerated packages."})]})}function m(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},8453(e,n,s){s.d(n,{R:()=>t,x:()=>r});var a=s(6540);const i={},o=a.createContext(i);function t(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);